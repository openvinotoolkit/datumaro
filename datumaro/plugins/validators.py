# Copyright (C) 2021 Intel Corporation
#
# SPDX-License-Identifier: MIT

import argparse
import json
import logging as log
import numpy as np
from copy import deepcopy

from datumaro.components.validator import (Severity, TaskType, Validator)
from datumaro.components.cli_plugin import CliPlugin
from datumaro.components.dataset import IDataset
from datumaro.components.errors import MultiLabelAnnotations, NegativeLength
from datumaro.components.extractor import AnnotationType, LabelCategories

class Classification(Validator, CliPlugin):
    """
    A specific validator class for classification task.
    """
    @classmethod
    def build_cmdline_parser(cls, **kwargs):
        parser = super().build_cmdline_parser(**kwargs)
        parser.add_argument('-fs', '--few_samples_thr', default=1, type=int,
            help="Threshold for giving a warning for minimum number of"
                 "samples per class")
        parser.add_argument('-ir', '--imbalance_ratio_thr', default=50, type=int,
            help="Threshold for giving data imbalance warning;"
                 "IR(imbalance ratio) = majority/minority")
        parser.add_argument('-m', '--far_from_mean_thr', default=5.0, type=float,
            help="Threshold for giving a warning that data is far from mean;"
                 "A constant used to define mean +/- k * standard deviation;")
        parser.add_argument('-dr', '--dominance_ratio_thr', default=0.8, type=float,
            help="Threshold for giving a warning for bounding box imbalance;"
                "Dominace_ratio = ratio of Top-k bin to total in histogram;")
        parser.add_argument('-k', '--topk_bins', default=0.1, type=float,
            help="Ratio of bins with the highest number of data"
                 "to total bins in the histogram; [0, 1]; 0.1 = 10%;")
        return parser

    def __init__(self, few_samples_thr, imbalance_ratio_thr,
            far_from_mean_thr, dominance_ratio_thr, topk_bins):
        super().__init__(task_type=TaskType.classification,
            few_samples_thr=few_samples_thr,
            imbalance_ratio_thr=imbalance_ratio_thr,
            far_from_mean_thr=far_from_mean_thr,
            dominance_ratio_thr=dominance_ratio_thr, topk_bins=topk_bins)

    def _check_multi_label_annotations(self, stats):
        validation_reports = []

        items_with_multiple_labels = stats['items_with_multiple_labels']
        for item_id, item_subset in items_with_multiple_labels:
            validation_reports += self._generate_validation_report(
                MultiLabelAnnotations, Severity.error, item_id, item_subset)

        return validation_reports

    def compute_statistics(self, dataset):
        """
        Computes statistics of the dataset for the classification task.

        Parameters
        ----------
        dataset : IDataset object

        Returns
        -------
        stats (dict): A dict object containing statistics of the dataset.
        """

        stats, filtered_anns = self._compute_common_statistics(dataset)

        stats['items_with_multiple_labels'] = []

        for item_key, anns in filtered_anns:
            ann_count = len(anns)
            if ann_count > 1:
                stats['items_with_multiple_labels'].append(item_key)

        return stats

    def generate_reports(self, stats):
        """
        Validates the dataset for classification tasks based on its statistics.

        Parameters
        ----------
        dataset : IDataset object
        stats: Dict object

        Returns
        -------
        reports (list): List of validation reports (DatasetValidationError).
        """

        reports = []

        reports += self._check_missing_label_categories(stats)
        reports += self._check_missing_annotation(stats)
        reports += self._check_multi_label_annotations(stats)
        reports += self._check_label_defined_but_not_found(stats)
        reports += self._check_only_one_label(stats)
        reports += self._check_few_samples_in_label(stats)
        reports += self._check_imbalanced_labels(stats)

        label_dist = stats['label_distribution']
        attr_dist = stats['attribute_distribution']
        defined_attr_dist = attr_dist['defined_attributes']
        undefined_label_dist = label_dist['undefined_labels']
        undefined_attr_dist = attr_dist['undefined_attributes']

        defined_labels = defined_attr_dist.keys()
        for label_name in defined_labels:
            attr_stats = defined_attr_dist[label_name]

            reports += self._check_attribute_defined_but_not_found(
                label_name, attr_stats)

            for attr_name, attr_dets in attr_stats.items():
                reports += self._check_few_samples_in_attribute(
                    label_name, attr_name, attr_dets)
                reports += self._check_imbalanced_attribute(
                    label_name, attr_name, attr_dets)
                reports += self._check_only_one_attribute_value(
                    label_name, attr_name, attr_dets)
                reports += self._check_missing_attribute(
                    label_name, attr_name, attr_dets)

        for label_name, label_stats in undefined_label_dist.items():
            reports += self._check_undefined_label(label_name, label_stats)

        for label_name, attr_stats in undefined_attr_dist.items():
            for attr_name, attr_dets in attr_stats.items():
                reports += self._check_undefined_attribute(
                    label_name, attr_name, attr_dets)

        return reports

class Detection(Validator, CliPlugin):
    """
    A specific validator class for detection task.
    """
    @classmethod
    def build_cmdline_parser(cls, **kwargs):
        parser = super().build_cmdline_parser(**kwargs)
        parser.add_argument('-fs', '--few_samples_thr', default=1, type=int,
            help="Threshold for giving a warning for minimum number of"
                 "samples per class")
        parser.add_argument('-ir', '--imbalance_ratio_thr', default=50, type=int,
            help="Threshold for giving data imbalance warning;"
                 "IR(imbalance ratio) = majority/minority")
        parser.add_argument('-m', '--far_from_mean_thr', default=5.0, type=float,
            help="Threshold for giving a warning that data is far from mean;"
                 "A constant used to define mean +/- k * standard deviation;")
        parser.add_argument('-dr', '--dominance_ratio_thr', default=0.8, type=float,
            help="Threshold for giving a warning for bounding box imbalance;"
                "Dominace_ratio = ratio of Top-k bin to total in histogram;")
        parser.add_argument('-k', '--topk_bins', default=0.1, type=float,
            help="Ratio of bins with the highest number of data"
                 "to total bins in the histogram; [0, 1]; 0.1 = 10%;")
        return parser

    def __init__(self, few_samples_thr, imbalance_ratio_thr,
            far_from_mean_thr, dominance_ratio_thr, topk_bins):
        super().__init__(task_type=TaskType.detection,
            few_samples_thr=few_samples_thr,
            imbalance_ratio_thr=imbalance_ratio_thr,
            far_from_mean_thr=far_from_mean_thr,
            dominance_ratio_thr=dominance_ratio_thr, topk_bins=topk_bins)

    def _check_negative_length(self, stats):
        validation_reports = []

        items_w_neg_len = stats['items_with_negative_length']
        for item_dets, anns_w_neg_len in items_w_neg_len.items():
            item_id, item_subset = item_dets
            for ann_id, props in anns_w_neg_len.items():
                for prop, val in props.items():
                    val = round(val, 2)
                    details = (item_subset, ann_id,
                               f"{self.str_ann_type} {prop}", val)
                    validation_reports += self._generate_validation_report(
                        NegativeLength, Severity.error, item_id, *details)

        return validation_reports

    def compute_statistics(self, dataset):
        """
        Computes statistics of the dataset for the detection task.

        Parameters
        ----------
        dataset : IDataset object

        Returns
        -------
        stats (dict): A dict object containing statistics of the dataset.
        """

        stats, filtered_anns = self._compute_common_statistics(dataset)

        # detection-specific
        bbox_template = {
            'width': deepcopy(self.numerical_stat_template),
            'height': deepcopy(self.numerical_stat_template),
            'area(wxh)': deepcopy(self.numerical_stat_template),
            'ratio(w/h)': deepcopy(self.numerical_stat_template),
            'short': deepcopy(self.numerical_stat_template),
            'long': deepcopy(self.numerical_stat_template)
        }

        stats['items_with_negative_length'] = {}
        stats['items_with_invalid_value'] = {}
        stats['bbox_distribution_in_label'] = {}
        stats['bbox_distribution_in_attribute'] = {}
        stats['bbox_distribution_in_dataset_item'] = {}

        dist_by_label = stats['bbox_distribution_in_label']
        dist_by_attr = stats['bbox_distribution_in_attribute']
        bbox_dist_in_item = stats['bbox_distribution_in_dataset_item']
        items_w_neg_len = stats['items_with_negative_length']
        items_w_invalid_val = stats['items_with_invalid_value']

        def _generate_ann_bbox_info(_x, _y, _w, _h, area,
                                    ratio, _short, _long):
            return {
                'x': _x,
                'y': _y,
                'width': _w,
                'height': _h,
                'area(wxh)': area,
                'ratio(w/h)': ratio,
                'short': _short,
                'long': _long,
            }

        def _update_bbox_stats_by_label(item_key, ann, bbox_label_stats):
            bbox_has_error = False

            _x, _y, _w, _h = ann.get_bbox()
            area = ann.get_area()

            if _h != 0 and _h != float('inf'):
                ratio = _w / _h
            else:
                ratio = float('nan')

            _short = _w if _w < _h else _h
            _long = _w if _w > _h else _h

            ann_bbox_info = _generate_ann_bbox_info(
                _x, _y, _w, _h, area, ratio, _short, _long)

            for prop, val in ann_bbox_info.items():
                if val == float('inf') or np.isnan(val):
                    bbox_has_error = True
                    anns_w_invalid_val = items_w_invalid_val.setdefault(
                        item_key, {})
                    invalid_props = anns_w_invalid_val.setdefault(
                        ann.id, [])
                    invalid_props.append(prop)

            for prop in ['width', 'height']:
                val = ann_bbox_info[prop]
                if val < 1:
                    bbox_has_error = True
                    anns_w_neg_len = items_w_neg_len.setdefault(
                        item_key, {})
                    neg_props = anns_w_neg_len.setdefault(ann.id, {})
                    neg_props[prop] = val

            if not bbox_has_error:
                ann_bbox_info.pop('x')
                ann_bbox_info.pop('y')
                self._update_prop_distributions(ann_bbox_info, bbox_label_stats)

            return ann_bbox_info, bbox_has_error

        label_categories = dataset.categories().get(AnnotationType.label,
            LabelCategories())
        base_valid_attrs = label_categories.attributes

        for item_key, annotations in filtered_anns:
            ann_count = len(annotations)

            bbox_dist_in_item[item_key] = ann_count

            for ann in annotations:
                if not 0 <= ann.label < len(label_categories):
                    label_name = ann.label
                    valid_attrs = set()
                else:
                    label_name = label_categories[ann.label].name
                    valid_attrs = base_valid_attrs.union(
                        label_categories[ann.label].attributes)

                    bbox_label_stats = dist_by_label.setdefault(
                        label_name, deepcopy(bbox_template))
                    ann_bbox_info, bbox_has_error = \
                        _update_bbox_stats_by_label(
                            item_key, ann, bbox_label_stats)

                for attr, value in ann.attributes.items():
                    if attr in valid_attrs:
                        bbox_attr_label = dist_by_attr.setdefault(
                            label_name, {})
                        bbox_attr_stats = bbox_attr_label.setdefault(
                            attr, {})
                        bbox_val_stats = bbox_attr_stats.setdefault(
                            str(value), deepcopy(bbox_template))

                        if not bbox_has_error:
                            self._update_prop_distributions(
                                ann_bbox_info, bbox_val_stats)

        # Compute prop stats from distribution
        self._compute_prop_stats_from_dist(dist_by_label, dist_by_attr)

        def _is_valid_ann(item_key, ann):
            has_defined_label = 0 <= ann.label < len(label_categories)
            if not has_defined_label:
                return False

            bbox_has_neg_len = ann.id in items_w_neg_len.get(
                item_key, {})
            bbox_has_invalid_val = ann.id in items_w_invalid_val.get(
                item_key, {})
            return not (bbox_has_neg_len or bbox_has_invalid_val)

        def _update_props_far_from_mean(item_key, ann):
            valid_attrs = base_valid_attrs.union(
                label_categories[ann.label].attributes)
            label_name = label_categories[ann.label].name
            bbox_label_stats = dist_by_label[label_name]

            _x, _y, _w, _h = ann.get_bbox()
            area = ann.get_area()
            ratio = _w / _h
            _short = _w if _w < _h else _h
            _long = _w if _w > _h else _h

            ann_bbox_info = _generate_ann_bbox_info(
                _x, _y, _w, _h, area, ratio, _short, _long)
            ann_bbox_info.pop('x')
            ann_bbox_info.pop('y')

            for prop, val in ann_bbox_info.items():
                prop_stats = bbox_label_stats[prop]
                self._compute_far_from_mean(prop_stats, val, item_key, ann)

            for attr, value in ann.attributes.items():
                if attr in valid_attrs:
                    bbox_attr_stats = dist_by_attr[label_name][attr]
                    bbox_val_stats = bbox_attr_stats[str(value)]

                    for prop, val in ann_bbox_info.items():
                        prop_stats = bbox_val_stats[prop]
                        self._compute_far_from_mean(prop_stats, val,
                                                    item_key, ann)

        for item_key, annotations in filtered_anns:
            for ann in annotations:
                if _is_valid_ann(item_key, ann):
                    _update_props_far_from_mean(item_key, ann)

        return stats

    def generate_reports(self, stats):
        """
        Validates the dataset for detection tasks based on its statistics.

        Parameters
        ----------
        dataset : IDataset object
        stats : Dict object

        Returns
        -------
        reports (list): List of validation reports (DatasetValidationError).
        """

        reports = []

        reports += self._check_missing_label_categories(stats)
        reports += self._check_missing_annotation(stats)
        reports += self._check_label_defined_but_not_found(stats)
        reports += self._check_only_one_label(stats)
        reports += self._check_few_samples_in_label(stats)
        reports += self._check_imbalanced_labels(stats)
        reports += self._check_negative_length(stats)
        reports += self._check_invalid_value(stats)

        label_dist = stats['label_distribution']
        attr_dist = stats['attribute_distribution']
        defined_attr_dist = attr_dist['defined_attributes']
        undefined_label_dist = label_dist['undefined_labels']
        undefined_attr_dist = attr_dist['undefined_attributes']

        dist_by_label = stats['bbox_distribution_in_label']
        dist_by_attr = stats['bbox_distribution_in_attribute']

        defined_labels = defined_attr_dist.keys()
        for label_name in defined_labels:
            attr_stats = defined_attr_dist[label_name]

            reports += self._check_attribute_defined_but_not_found(
                label_name, attr_stats)

            for attr_name, attr_dets in attr_stats.items():
                reports += self._check_few_samples_in_attribute(
                    label_name, attr_name, attr_dets)
                reports += self._check_imbalanced_attribute(
                    label_name, attr_name, attr_dets)
                reports += self._check_only_one_attribute_value(
                    label_name, attr_name, attr_dets)
                reports += self._check_missing_attribute(
                    label_name, attr_name, attr_dets)

            bbox_label_stats = dist_by_label[label_name]
            bbox_attr_label = dist_by_attr.get(label_name, {})

            reports += self._check_far_from_label_mean(
                label_name, bbox_label_stats)
            reports += self._check_imbalanced_dist_in_label(
                label_name, bbox_label_stats)

            for attr_name, bbox_attr_stats in bbox_attr_label.items():
                reports += self._check_far_from_attr_mean(
                    label_name, attr_name, bbox_attr_stats)
                reports += self._check_imbalanced_dist_in_attr(
                    label_name, attr_name, bbox_attr_stats)

        for label_name, label_stats in undefined_label_dist.items():
            reports += self._check_undefined_label(label_name, label_stats)

        for label_name, attr_stats in undefined_attr_dist.items():
            for attr_name, attr_dets in attr_stats.items():
                reports += self._check_undefined_attribute(
                    label_name, attr_name, attr_dets)

        return reports

class Segmentation(Validator, CliPlugin):
    """
    A specific validator class for (instance) segmentation task.
    """
    @classmethod
    def build_cmdline_parser(cls, **kwargs):
        parser = super().build_cmdline_parser(**kwargs)
        parser.add_argument('-fs', '--few_samples_thr', default=1, type=int,
            help="Threshold for giving a warning for minimum number of"
                 "samples per class")
        parser.add_argument('-ir', '--imbalance_ratio_thr', default=50, type=int,
            help="Threshold for giving data imbalance warning;"
                 "IR(imbalance ratio) = majority/minority")
        parser.add_argument('-m', '--far_from_mean_thr', default=5.0, type=float,
            help="Threshold for giving a warning that data is far from mean;"
                 "A constant used to define mean +/- k * standard deviation;")
        parser.add_argument('-dr', '--dominance_ratio_thr', default=0.8, type=float,
            help="Threshold for giving a warning for bounding box imbalance;"
                "Dominace_ratio = ratio of Top-k bin to total in histogram;")
        parser.add_argument('-k', '--topk_bins', default=0.1, type=float,
            help="Ratio of bins with the highest number of data"
                 "to total bins in the histogram; [0, 1]; 0.1 = 10%;")
        return parser

    def __init__(self, few_samples_thr, imbalance_ratio_thr,
            far_from_mean_thr, dominance_ratio_thr, topk_bins):
        super().__init__(task_type=TaskType.segmentation,
            few_samples_thr=few_samples_thr,
            imbalance_ratio_thr=imbalance_ratio_thr,
            far_from_mean_thr=far_from_mean_thr,
            dominance_ratio_thr=dominance_ratio_thr, topk_bins=topk_bins)

    def compute_statistics(self, dataset):
        """
        Computes statistics of the dataset for the segmentation task.

        Parameters
        ----------
        dataset : IDataset object

        Returns
        -------
        stats (dict): A dict object containing statistics of the dataset.
        """

        stats, filtered_anns = self._compute_common_statistics(dataset)

        # segmentation-specific
        mask_template = {
            'area': deepcopy(self.numerical_stat_template),
            'width': deepcopy(self.numerical_stat_template),
            'height': deepcopy(self.numerical_stat_template)
        }

        stats['items_with_invalid_value'] = {}
        stats['mask_distribution_in_label'] = {}
        stats['mask_distribution_in_attribute'] = {}
        stats['mask_distribution_in_dataset_item'] = {}

        dist_by_label = stats['mask_distribution_in_label']
        dist_by_attr = stats['mask_distribution_in_attribute']
        mask_dist_in_item = stats['mask_distribution_in_dataset_item']
        items_w_invalid_val = stats['items_with_invalid_value']

        def _generate_ann_mask_info(area, _w, _h):
            return {
                'area': area,
                'width': _w,
                'height': _h,
            }

        def _update_mask_stats_by_label(item_key, ann, mask_label_stats):
            mask_has_error = False

            _x, _y, _w, _h = ann.get_bbox()

            # Detete the following block when #226 is resolved
            # https://github.com/openvinotoolkit/datumaro/issues/226
            if ann.type == AnnotationType.mask:
                _w += 1
                _h += 1

            area = ann.get_area()

            ann_mask_info = _generate_ann_mask_info(area, _w, _h)

            for prop, val in ann_mask_info.items():
                if val == float('inf') or np.isnan(val):
                    mask_has_error = True
                    anns_w_invalid_val = items_w_invalid_val.setdefault(
                        item_key, {})
                    invalid_props = anns_w_invalid_val.setdefault(
                        ann.id, [])
                    invalid_props.append(prop)

            if not mask_has_error:
                self._update_prop_distributions(ann_mask_info, mask_label_stats)

            return ann_mask_info, mask_has_error

        label_categories = dataset.categories().get(AnnotationType.label,
            LabelCategories())
        base_valid_attrs = label_categories.attributes

        for item_key, annotations in filtered_anns:
            ann_count = len(annotations)
            mask_dist_in_item[item_key] = ann_count

            for ann in annotations:
                if not 0 <= ann.label < len(label_categories):
                    label_name = ann.label
                    valid_attrs = set()
                else:
                    label_name = label_categories[ann.label].name
                    valid_attrs = base_valid_attrs.union(
                        label_categories[ann.label].attributes)

                    mask_label_stats = dist_by_label.setdefault(
                        label_name, deepcopy(mask_template))
                    ann_mask_info, mask_has_error = \
                        _update_mask_stats_by_label(
                            item_key, ann, mask_label_stats)

                for attr, value in ann.attributes.items():
                    if attr in valid_attrs:
                        mask_attr_label = dist_by_attr.setdefault(
                            label_name, {})
                        mask_attr_stats = mask_attr_label.setdefault(
                            attr, {})
                        mask_val_stats = mask_attr_stats.setdefault(
                            str(value), deepcopy(mask_template))

                        if not mask_has_error:
                            self._update_prop_distributions(
                                ann_mask_info, mask_val_stats)

        # compute prop stats from dist.
        self._compute_prop_stats_from_dist(dist_by_label, dist_by_attr)

        def _is_valid_ann(item_key, ann):
            has_defined_label = 0 <= ann.label < len(label_categories)
            if not has_defined_label:
                return False

            mask_has_invalid_val = ann.id in items_w_invalid_val.get(
                item_key, {})
            return not mask_has_invalid_val

        def _update_props_far_from_mean(item_key, ann):
            valid_attrs = base_valid_attrs.union(
                label_categories[ann.label].attributes)
            label_name = label_categories[ann.label].name
            mask_label_stats = dist_by_label[label_name]

            _x, _y, _w, _h = ann.get_bbox()

            # Detete the following block when #226 is resolved
            # https://github.com/openvinotoolkit/datumaro/issues/226
            if ann.type == AnnotationType.mask:
                _w += 1
                _h += 1
            area = ann.get_area()

            ann_mask_info = _generate_ann_mask_info(area, _w, _h)

            for prop, val in ann_mask_info.items():
                prop_stats = mask_label_stats[prop]
                self._compute_far_from_mean(prop_stats, val, item_key, ann)

            for attr, value in ann.attributes.items():
                if attr in valid_attrs:
                    mask_attr_stats = dist_by_attr[label_name][attr]
                    mask_val_stats = mask_attr_stats[str(value)]

                    for prop, val in ann_mask_info.items():
                        prop_stats = mask_val_stats[prop]
                        self._compute_far_from_mean(prop_stats, val,
                                                    item_key, ann)

        for item_key, annotations in filtered_anns:
            for ann in annotations:
                if _is_valid_ann(item_key, ann):
                    _update_props_far_from_mean(item_key, ann)

        return stats

    def generate_reports(self, stats):
        """
        Validates the dataset for segmentation tasks based on its statistics.

        Parameters
        ----------
        dataset : IDataset object
        stats : Dict object

        Returns
        -------
        reports (list): List of validation reports (DatasetValidationError).
        """

        reports = []

        reports += self._check_missing_label_categories(stats)
        reports += self._check_missing_annotation(stats)
        reports += self._check_label_defined_but_not_found(stats)
        reports += self._check_only_one_label(stats)
        reports += self._check_few_samples_in_label(stats)
        reports += self._check_imbalanced_labels(stats)
        reports += self._check_invalid_value(stats)

        label_dist = stats['label_distribution']
        attr_dist = stats['attribute_distribution']
        defined_attr_dist = attr_dist['defined_attributes']
        undefined_label_dist = label_dist['undefined_labels']
        undefined_attr_dist = attr_dist['undefined_attributes']

        dist_by_label = stats['mask_distribution_in_label']
        dist_by_attr = stats['mask_distribution_in_attribute']

        defined_labels = defined_attr_dist.keys()
        for label_name in defined_labels:
            attr_stats = defined_attr_dist[label_name]

            reports += self._check_attribute_defined_but_not_found(
                label_name, attr_stats)

            for attr_name, attr_dets in attr_stats.items():
                reports += self._check_few_samples_in_attribute(
                    label_name, attr_name, attr_dets)
                reports += self._check_imbalanced_attribute(
                    label_name, attr_name, attr_dets)
                reports += self._check_only_one_attribute_value(
                    label_name, attr_name, attr_dets)
                reports += self._check_missing_attribute(
                    label_name, attr_name, attr_dets)

            mask_label_stats = dist_by_label[label_name]
            mask_attr_label = dist_by_attr.get(label_name, {})

            reports += self._check_far_from_label_mean(
                label_name, mask_label_stats)
            reports += self._check_imbalanced_dist_in_label(
                label_name, mask_label_stats)

            for attr_name, mask_attr_stats in mask_attr_label.items():
                reports += self._check_far_from_attr_mean(
                    label_name, attr_name, mask_attr_stats)
                reports += self._check_imbalanced_dist_in_attr(
                    label_name, attr_name, mask_attr_stats)

        for label_name, label_stats in undefined_label_dist.items():
            reports += self._check_undefined_label(label_name, label_stats)

        for label_name, attr_stats in undefined_attr_dist.items():
            for attr_name, attr_dets in attr_stats.items():
                reports += self._check_undefined_attribute(
                    label_name, attr_name, attr_dets)

        return reports
