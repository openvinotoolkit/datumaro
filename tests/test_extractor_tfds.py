import os.path as osp
from unittest.case import TestCase, skipIf

import numpy as np

from datumaro.components.annotation import Bbox, Label
from datumaro.components.dataset import Dataset
from datumaro.components.environment import Environment
from datumaro.components.extractor import DatasetItem
from datumaro.components.extractor_tfds import AVAILABLE_TFDS_DATASETS, TFDS_EXTRACTOR_AVAILABLE
from datumaro.components.media import Image, MediaElement
from datumaro.util.image import decode_image, encode_image
from datumaro.util.test_utils import compare_datasets, mock_tfds_data

from tests.requirements import Requirements, mark_requirement

if TFDS_EXTRACTOR_AVAILABLE:
    import tensorflow_datasets as tfds


class TfdsDatasetsTest(TestCase):
    @mark_requirement(Requirements.DATUM_GENERAL_REQ)
    def test_metadata(self):
        env = Environment()

        for dataset in AVAILABLE_TFDS_DATASETS.values():
            assert isinstance(dataset.metadata.human_name, str)
            assert dataset.metadata.human_name != ""

            assert dataset.metadata.default_output_format in env.converters

            assert issubclass(dataset.metadata.media_type, MediaElement)

            # The home URL is optional, but currently every dataset has one.
            assert isinstance(dataset.metadata.home_url, str)
            assert dataset.metadata.home_url != ""

    @mark_requirement(Requirements.DATUM_GENERAL_REQ)
    def test_remote_metadata(self):
        with mock_tfds_data():
            dataset = AVAILABLE_TFDS_DATASETS["mnist"]

            remote_meta = dataset.query_remote_metadata()

            # verify that the remote metadata contains a copy of the local metadata
            for attribute in dataset.metadata.__attrs_attrs__:
                assert getattr(dataset.metadata, attribute.name) == getattr(
                    remote_meta, attribute.name
                )

            tfds_info = tfds.builder("mnist").info

            assert remote_meta.description == tfds_info.description
            assert remote_meta.download_size == tfds_info.download_size
            assert remote_meta.num_classes == len(tfds_info.features["label"].names)
            assert remote_meta.version == tfds_info.version

            assert len(remote_meta.subsets) == len(tfds_info.splits)

            for split_name, split in tfds_info.splits.items():
                assert remote_meta.subsets[split_name].num_items == sum(split.shard_lengths)


@skipIf(not TFDS_EXTRACTOR_AVAILABLE, reason="TFDS is not installed")
class TfdsExtractorTest(TestCase):
    @mark_requirement(Requirements.DATUM_GENERAL_REQ)
    def test_data_access(self):
        with mock_tfds_data(subsets=("train", "val")):
            extractor = AVAILABLE_TFDS_DATASETS["mnist"].make_extractor()
            self.assertEqual(len(extractor), 2)

            expected_train_subset = Dataset(extractor).filter("/item[subset = 'train']")

            compare_datasets(self, expected_train_subset, Dataset(extractor.get_subset("train")))

            self.assertRaises(KeyError, extractor.get_subset, "test")

            subsets = extractor.subsets()
            self.assertEqual(["train", "val"], sorted(subsets))
            compare_datasets(self, expected_train_subset, Dataset(subsets["train"]))

            self.assertIsNotNone(extractor.get("0"))
            self.assertIsNotNone(extractor.get("0", subset="train"))
            self.assertIsNotNone(extractor.get("0", subset="val"))
            self.assertIsNone(extractor.get("x"))
            self.assertIsNone(extractor.get("0", subset="test"))

    @mark_requirement(Requirements.DATUM_GENERAL_REQ)
    def test_can_extract_mnist(self):
        with mock_tfds_data():
            tfds_ds, tfds_info = tfds.load("mnist", split="train", with_info=True)
            tfds_example = next(iter(tfds_ds))

            expected_dataset = Dataset.from_iterable(
                [
                    DatasetItem(
                        id="0",
                        subset="train",
                        media=Image(data=tfds_example["image"].numpy().squeeze(axis=2)),
                        annotations=[Label(tfds_example["label"].numpy())],
                    ),
                ],
                categories=tfds_info.features["label"].names,
            )

            extractor = AVAILABLE_TFDS_DATASETS["mnist"].make_extractor()
            actual_dataset = Dataset(extractor)

            compare_datasets(self, expected_dataset, actual_dataset, require_media=True)

    def _test_can_extract_cifar(self, name):
        with mock_tfds_data():
            tfds_ds, tfds_info = tfds.load(name, split="train", with_info=True)
            tfds_example = next(iter(tfds_ds))

            expected_dataset = Dataset.from_iterable(
                [
                    DatasetItem(
                        id=tfds_example["id"].numpy().decode("UTF-8"),
                        subset="train",
                        media=Image(data=tfds_example["image"].numpy()[..., ::-1]),
                        annotations=[Label(tfds_example["label"].numpy())],
                    ),
                ],
                categories=tfds_info.features["label"].names,
            )

            extractor = AVAILABLE_TFDS_DATASETS[name].make_extractor()
            actual_dataset = Dataset(extractor)

            compare_datasets(self, expected_dataset, actual_dataset, require_media=True)

    @mark_requirement(Requirements.DATUM_GENERAL_REQ)
    def test_can_extract_cifar10(self):
        self._test_can_extract_cifar("cifar10")

    @mark_requirement(Requirements.DATUM_GENERAL_REQ)
    def test_can_extract_cifar100(self):
        self._test_can_extract_cifar("cifar100")

    @mark_requirement(Requirements.DATUM_GENERAL_REQ)
    def test_can_extract_coco(self):
        tfds_example = {
            "image": encode_image(np.ones((20, 10)), ".png"),
            "image/filename": "test.png",
            "image/id": 123,
            "objects": {
                "bbox": [[0.1, 0.2, 0.3, 0.4]],
                "label": [5],
                "is_crowd": [True],
            },
        }

        with mock_tfds_data(example=tfds_example):
            tfds_info = tfds.builder("coco/2014").info

            expected_dataset = Dataset.from_iterable(
                [
                    DatasetItem(
                        id="test",
                        subset="train",
                        media=Image(data=np.ones((20, 10))),
                        annotations=[
                            Bbox(2, 2, 2, 4, label=5, attributes={"is_crowd": True}),
                        ],
                        attributes={"id": 123},
                    ),
                ],
                categories=tfds_info.features["objects"].feature["label"].names,
            )

            extractor = AVAILABLE_TFDS_DATASETS["coco/2014"].make_extractor()
            actual_dataset = Dataset(extractor)

            compare_datasets(self, expected_dataset, actual_dataset, require_media=True)

    @mark_requirement(Requirements.DATUM_GENERAL_REQ)
    def test_can_extract_imagenet_v2(self):
        with mock_tfds_data():
            tfds_ds, tfds_info = tfds.load(
                "imagenet_v2",
                split="train",
                with_info=True,
                # We can't let TFDS decode the image for us, because:
                # a) imagenet_v2 produces JPEG-encoded images;
                # b) TFDS decodes them via TensorFlow;
                # c) Datumaro decodes them via OpenCV.
                # So for the decoded results to match, we have to decode
                # them via OpenCV as well.
                decoders={"image": tfds.decode.SkipDecoding()},
            )
            tfds_example = next(iter(tfds_ds))

            example_file_name = tfds_example["file_name"].numpy().decode("UTF-8")

            expected_dataset = Dataset.from_iterable(
                [
                    DatasetItem(
                        id=osp.splitext(example_file_name)[0],
                        subset="train",
                        media=Image(
                            data=decode_image(tfds_example["image"].numpy()),
                            path=example_file_name,
                        ),
                        annotations=[Label(tfds_example["label"].numpy())],
                    ),
                ],
                categories=tfds_info.features["label"].names,
            )

            extractor = AVAILABLE_TFDS_DATASETS["imagenet_v2"].make_extractor()
            actual_dataset = Dataset(extractor)

            compare_datasets(self, expected_dataset, actual_dataset, require_media=True)

    @mark_requirement(Requirements.DATUM_GENERAL_REQ)
    def test_can_extract_voc(self):
        # TFDS is unable to generate fake examples for object detection
        # datasets. See <https://github.com/tensorflow/datasets/issues/3633>.
        tfds_example = {
            "image/filename": "test.png",
            "image": encode_image(np.ones((20, 10)), ".png"),
            "objects": {
                "bbox": [[0.1, 0.2, 0.3, 0.4]],
                "label": [5],
                "is_difficult": [True],
                "is_truncated": [False],
                "pose": [0],
            },
        }

        with mock_tfds_data(example=tfds_example):
            tfds_info = tfds.builder("voc/2012").info

            pose_names = tfds_info.features["objects"].feature["pose"].names

            expected_dataset = Dataset.from_iterable(
                [
                    DatasetItem(
                        id="test",
                        subset="train",
                        media=Image(data=np.ones((20, 10))),
                        annotations=[
                            Bbox(
                                2,
                                2,
                                2,
                                4,
                                label=5,
                                attributes={
                                    "difficult": True,
                                    "truncated": False,
                                    "pose": pose_names[0].title(),
                                },
                            ),
                        ],
                    ),
                ],
                categories=tfds_info.features["objects"].feature["label"].names,
            )

            extractor = AVAILABLE_TFDS_DATASETS["voc/2012"].make_extractor()
            actual_dataset = Dataset(extractor)

            compare_datasets(self, expected_dataset, actual_dataset, require_media=True)
