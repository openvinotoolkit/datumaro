{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c0b77ed",
   "metadata": {},
   "source": [
    "### Merge Heterogeneous Datasets for Detection\n",
    "Datumaro supports merging heterogeneous datasets into a unified data foramt.\n",
    "\n",
    "In this document, we import two heterogeneous datasets and export a merged dataset into a unified data format.\n",
    "First, we import two sample datasets that the data formats of them are COCO detection, VOC detection, respectively.\n",
    "Then, we will export the merged dataset as Yolo format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c962a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2021 Intel Corporation\n",
    "#\n",
    "# SPDX-License-Identifier: MIT\n",
    "\n",
    "import os\n",
    "import datumaro as dm\n",
    "from datumaro.components.operations import IntersectMerge\n",
    "from datumaro.components.operations import compute_image_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c8da69",
   "metadata": {},
   "source": [
    "We export sample COCO dataset and VOC datasets seperately.\n",
    "Note that we can omitt passing 'format' parameter.\n",
    "Without the explicit format parameter, Datumaro will dectect the proper dataset format automatically.\n",
    "\n",
    "Since we only interest in COCO instances data, the other annotations (such that labels, stuff, ...) are ignored.\n",
    "Datumaro will print warning message during import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9afcb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/labels_train.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/labels_val.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/stuff_val.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/panoptic_train.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/person_keypoints_val.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/stuff_train.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/image_info_train.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/person_keypoints_train.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/captions_val.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/captions_train.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/image_info_val.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/panoptic_val.json' was skipped, could't match this file with any of these tasks: coco_instances\n"
     ]
    }
   ],
   "source": [
    "dataset_coco = dm.Dataset.import_from('../tests/assets/coco_dataset/coco', format='coco_instances')\n",
    "dataset_voc = dm.Dataset.import_from('../tests/assets/voc_dataset/voc_dataset1', format='voc_detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99699f7",
   "metadata": {},
   "source": [
    "In the sample COCO dataset, there are 2 images where each image is divided into 'train' and 'val' subset.\n",
    "In the sample VOC dataset, 1 image to 'train' subset and 1 image to 'test' subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ec535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics for a sample COCO dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': {'images count': 2,\n",
       "  'unique images count': 1,\n",
       "  'repeated images count': 1,\n",
       "  'repeated images': [[('a', 'train'), ('b', 'val')]]},\n",
       " 'subsets': {'val': {'images count': 1,\n",
       "   'image mean': [0.9999999999999987, 0.9999999999999987, 0.9999999999999987],\n",
       "   'image std': [6.361265799828938e-08,\n",
       "    6.361265799828938e-08,\n",
       "    6.361265799828938e-08]},\n",
       "  'train': {'images count': 1,\n",
       "   'image mean': [0.9999999999999987, 0.9999999999999987, 0.9999999999999987],\n",
       "   'image std': [6.361265799828938e-08,\n",
       "    6.361265799828938e-08,\n",
       "    6.361265799828938e-08]}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('statistics for a sample COCO dataset')\n",
    "compute_image_statistics(dataset_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb9f1b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics for a sample VOC dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': {'images count': 2,\n",
       "  'unique images count': 1,\n",
       "  'repeated images count': 1,\n",
       "  'repeated images': [[('2007_000001', 'train'), ('2007_000002', 'test')]]},\n",
       " 'subsets': {'test': {'images count': 1,\n",
       "   'image mean': [0.9999999999999971, 0.9999999999999971, 0.9999999999999971],\n",
       "   'image std': [9.411065220006367e-08,\n",
       "    9.411065220006367e-08,\n",
       "    9.411065220006367e-08]},\n",
       "  'train': {'images count': 1,\n",
       "   'image mean': [0.9999999999999971, 0.9999999999999971, 0.9999999999999971],\n",
       "   'image std': [9.411065220006367e-08,\n",
       "    9.411065220006367e-08,\n",
       "    9.411065220006367e-08]}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('statistics for a sample VOC dataset')\n",
    "compute_image_statistics(dataset_voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb66213",
   "metadata": {},
   "source": [
    "Since the target datasets are heterogeneous, we should call 'IntersectMerge' to merge them.\n",
    "In the merged dataset, there is a total of 4 images.\n",
    "We can see that the subsets of image are merged by the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a034674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics for the merged dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': {'images count': 4,\n",
       "  'unique images count': 2,\n",
       "  'repeated images count': 2,\n",
       "  'repeated images': [[('2007_000001', 'train'), ('2007_000002', 'test')],\n",
       "   [('a', 'train'), ('b', 'val')]]},\n",
       " 'subsets': {'train': {'images count': 2,\n",
       "   'image mean': [0.9999999999999978, 0.9999999999999978, 0.9999999999999978],\n",
       "   'image std': [8.873923033857324e-08,\n",
       "    8.873923033857324e-08,\n",
       "    8.873923033857324e-08]},\n",
       "  'test': {'images count': 1,\n",
       "   'image mean': [0.9999999999999971, 0.9999999999999971, 0.9999999999999971],\n",
       "   'image std': [9.411065220006367e-08,\n",
       "    9.411065220006367e-08,\n",
       "    9.411065220006367e-08]},\n",
       "  'val': {'images count': 1,\n",
       "   'image mean': [0.9999999999999987, 0.9999999999999987, 0.9999999999999987],\n",
       "   'image std': [6.361265799828938e-08,\n",
       "    6.361265799828938e-08,\n",
       "    6.361265799828938e-08]}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = IntersectMerge()(datasets=[dataset_coco, dataset_voc])\n",
    "\n",
    "print('statistics for the merged dataset')\n",
    "compute_image_statistics(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cfbba1",
   "metadata": {},
   "source": [
    "Finally, Datatum converts the dataset format to 'Yolo' and exports them to the 'merged_dataset' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7068310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\n",
      "-rw-rw-r-- 1 bonhun bonhun  116 10월  6 22:53 obj.data\n",
      "-rw-rw-r-- 1 bonhun bonhun  175 10월  6 22:53 obj.names\n",
      "drwxrwxr-x 2 bonhun bonhun 4096 10월  6 22:53 obj_test_data\n",
      "drwxrwxr-x 2 bonhun bonhun 4096 10월  6 22:53 obj_train_data\n",
      "drwxrwxr-x 2 bonhun bonhun 4096 10월  6 22:53 obj_val_data\n",
      "-rw-rw-r-- 1 bonhun bonhun   35 10월  6 22:53 test.txt\n",
      "-rw-rw-r-- 1 bonhun bonhun   62 10월  6 22:53 train.txt\n",
      "-rw-rw-r-- 1 bonhun bonhun   24 10월  6 22:53 val.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.export('merged_dataset', 'yolo')\n",
    "os.system('ls -l merged_dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c90c27300db58db001afd16f11e1f7b3963289e57b88abca6a1181a312b2e73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
