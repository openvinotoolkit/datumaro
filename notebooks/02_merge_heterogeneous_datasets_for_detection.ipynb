{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c0b77ed",
   "metadata": {},
   "source": [
    "### Merge Heterogeneous Datasets for Detection\n",
    "Datumaro supports merging heterogeneous datasets into a unified data format.\n",
    "\n",
    "In this document, we import two heterogeneous datasets and export a merged dataset into a unified data format.\n",
    "First, we import two sample datasets that the data formats of them are COCO detection, VOC detection, respectively.\n",
    "Then, we will export the merged dataset as `yolo` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c962a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2021 Intel Corporation\n",
    "#\n",
    "# SPDX-License-Identifier: MIT\n",
    "\n",
    "import datumaro as dm\n",
    "from datumaro.components.operations import IntersectMerge\n",
    "from datumaro.components.operations import compute_image_statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1c8da69",
   "metadata": {},
   "source": [
    "We export sample COCO dataset and VOC datasets seperately.\n",
    "Note that we can omit passing `format` parameter.\n",
    "Without the explicit format parameter, Datumaro will dectect the proper dataset format automatically.\n",
    "\n",
    "Since we only interest in COCO instances data, the other annotations (such that labels, stuff, ...) are ignored.\n",
    "Datumaro will print warning message during import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9afcb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/labels_train.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/labels_val.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/stuff_val.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/panoptic_train.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/person_keypoints_val.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/stuff_train.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/image_info_train.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/person_keypoints_train.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/captions_val.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/captions_train.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/image_info_val.json' was skipped, could't match this file with any of these tasks: coco_instances\n",
      "WARNING:root:File '../tests/assets/coco_dataset/coco/annotations/panoptic_val.json' was skipped, could't match this file with any of these tasks: coco_instances\n"
     ]
    }
   ],
   "source": [
    "dataset_coco = dm.Dataset.import_from(\"../tests/assets/coco_dataset/coco\", format=\"coco_instances\")\n",
    "dataset_voc = dm.Dataset.import_from(\n",
    "    \"../tests/assets/voc_dataset/voc_dataset1\", format=\"voc_detection\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d99699f7",
   "metadata": {},
   "source": [
    "In the sample COCO dataset, there are 2 images where each image is divided into `train` and `val` subset.\n",
    "In the sample VOC dataset, 1 image to `train` subset and 1 image to `test` subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ec535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics for a sample COCO dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': {'images count': 2,\n",
       "  'unique images count': 1,\n",
       "  'repeated images count': 1,\n",
       "  'repeated images': [[('a', 'train'), ('b', 'val')]]},\n",
       " 'subsets': {'val': {'images count': 1,\n",
       "   'image mean': [0.9999999999999987, 0.9999999999999987, 0.9999999999999987],\n",
       "   'image std': [6.361265799828938e-08,\n",
       "    6.361265799828938e-08,\n",
       "    6.361265799828938e-08]},\n",
       "  'train': {'images count': 1,\n",
       "   'image mean': [0.9999999999999987, 0.9999999999999987, 0.9999999999999987],\n",
       "   'image std': [6.361265799828938e-08,\n",
       "    6.361265799828938e-08,\n",
       "    6.361265799828938e-08]}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"statistics for a sample COCO dataset\")\n",
    "compute_image_statistics(dataset_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9f1b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics for a sample VOC dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': {'images count': 2,\n",
       "  'unique images count': 1,\n",
       "  'repeated images count': 1,\n",
       "  'repeated images': [[('2007_000001', 'train'), ('2007_000002', 'test')]]},\n",
       " 'subsets': {'test': {'images count': 1,\n",
       "   'image mean': [0.9999999999999971, 0.9999999999999971, 0.9999999999999971],\n",
       "   'image std': [9.411065220006367e-08,\n",
       "    9.411065220006367e-08,\n",
       "    9.411065220006367e-08]},\n",
       "  'train': {'images count': 1,\n",
       "   'image mean': [0.9999999999999971, 0.9999999999999971, 0.9999999999999971],\n",
       "   'image std': [9.411065220006367e-08,\n",
       "    9.411065220006367e-08,\n",
       "    9.411065220006367e-08]}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"statistics for a sample VOC dataset\")\n",
    "compute_image_statistics(dataset_voc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bb66213",
   "metadata": {},
   "source": [
    "Since the target datasets are heterogeneous, we should call `IntersectMerge` to merge them.\n",
    "In the merged dataset, there is a total of 4 images.\n",
    "We can see that the subsets of image are merged by the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a034674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics for the merged dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': {'images count': 4,\n",
       "  'unique images count': 2,\n",
       "  'repeated images count': 2,\n",
       "  'repeated images': [[('2007_000001', 'train'), ('2007_000002', 'test')],\n",
       "   [('a', 'train'), ('b', 'val')]]},\n",
       " 'subsets': {'train': {'images count': 2,\n",
       "   'image mean': [0.9999999999999978, 0.9999999999999978, 0.9999999999999978],\n",
       "   'image std': [8.873923033857324e-08,\n",
       "    8.873923033857324e-08,\n",
       "    8.873923033857324e-08]},\n",
       "  'test': {'images count': 1,\n",
       "   'image mean': [0.9999999999999971, 0.9999999999999971, 0.9999999999999971],\n",
       "   'image std': [9.411065220006367e-08,\n",
       "    9.411065220006367e-08,\n",
       "    9.411065220006367e-08]},\n",
       "  'val': {'images count': 1,\n",
       "   'image mean': [0.9999999999999987, 0.9999999999999987, 0.9999999999999987],\n",
       "   'image std': [6.361265799828938e-08,\n",
       "    6.361265799828938e-08,\n",
       "    6.361265799828938e-08]}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = IntersectMerge()(datasets=[dataset_coco, dataset_voc])\n",
    "\n",
    "print(\"statistics for the merged dataset\")\n",
    "compute_image_statistics(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0cfbba1",
   "metadata": {},
   "source": [
    "Finally, Datumaro converts the dataset format to `yolo` and exports them to the `merged_dataset` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7068310b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obj.data',\n",
       " 'obj.names',\n",
       " 'obj_test_data',\n",
       " 'obj_train_data',\n",
       " 'obj_val_data',\n",
       " 'test.txt',\n",
       " 'train.txt',\n",
       " 'val.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.export(\"merged_dataset\", \"yolo\")\n",
    "!ls merged_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c90c27300db58db001afd16f11e1f7b3963289e57b88abca6a1181a312b2e73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
